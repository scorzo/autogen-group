{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scorzo/autogen-group/blob/main/agentchat_groupchat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUNll_zItFAo"
      },
      "source": [
        "# Auto Generated Agent Chat: Group Chat\n",
        "\n",
        "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
        "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
        "\n",
        "This notebook is modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
        "\n",
        "## Requirements\n",
        "\n",
        "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
        "```bash\n",
        "pip install pyautogen\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nkwNaXNrtFAo"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "pip install \"pyautogen>=0.2.3\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Xh9-IQ3jRq",
        "outputId": "bc2c85b6-66a6-4e86-c877-e7f94a00a6ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLtq9gShtFAp"
      },
      "source": [
        "## Set your API Endpoint\n",
        "\n",
        "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-OQWiHhitFAp"
      },
      "outputs": [],
      "source": [
        "import autogen\n",
        "\n",
        "config_list_gpt4 = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gpt-4\"]\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YYFk_fItFAq"
      },
      "source": [
        "## Construct Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8lVL-N2_tFAr"
      },
      "outputs": [],
      "source": [
        "llm_config = {\"config_list\": config_list_gpt4, \"cache_seed\": 42}\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User_proxy\",\n",
        "    system_message=\"A human admin.\",\n",
        "    code_execution_config={\n",
        "        \"last_n_messages\": 2,\n",
        "        \"work_dir\": \"groupchat\",\n",
        "        \"use_docker\": False,\n",
        "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
        "    #human_input_mode=\"TERMINATE\",\n",
        "    human_input_mode=\"ALWAYS\",\n",
        ")\n",
        "coder = autogen.AssistantAgent(\n",
        "    name=\"Coder\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "pm = autogen.AssistantAgent(\n",
        "    name=\"Product_manager\",\n",
        "    system_message=\"Creative in software product ideas.\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "groupchat = autogen.GroupChat(\n",
        "    agents=[user_proxy, coder, pm],\n",
        "    messages=[],\n",
        "    max_round=12\n",
        "    #speaker_selection_method=\"manual\"  # Added to enable manual speaker selection.\n",
        ")\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Q9IYRitFAr"
      },
      "source": [
        "## Start Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vhsGbCn3tFAr",
        "outputId": "e4b0314d-0b99-4998-e63a-077b8045d2f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User_proxy (to chat_manager):\n",
            "\n",
            "Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Coder (to chat_manager):\n",
            "\n",
            "Before we can find a paper on GPT-4, let's first check if there's any paper uploaded on ArXiv about GPT-4. We can do this by scraping ArXiv's search results for \"GPT-4\". \n",
            "\n",
            "Here's a Python script that uses BeautifulSoup and Requests to scrape the titles and links of papers related to GPT-4 from ArXiv.\n",
            "\n",
            "```python\n",
            "# filename: arxiv_scraper.py\n",
            "\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "\n",
            "def get_arxiv_papers(query):\n",
            "    url = f'https://arxiv.org/search/?query={query}&searchtype=all'\n",
            "    response = requests.get(url)\n",
            "    soup = BeautifulSoup(response.text, 'html.parser')\n",
            "\n",
            "    articles = soup.select('li.arxiv-result')\n",
            "    papers = []\n",
            "\n",
            "    for article in articles:\n",
            "        title = article.select_one('p.title').text.strip()\n",
            "        link = 'https://arxiv.org' + article.select_one('p.list-title a').get('href')\n",
            "        papers.append((title, link))\n",
            "\n",
            "    return papers[0:5] # return the 5 latest papers\n",
            "\n",
            "papers_gpt4 = get_arxiv_papers('GPT-4')\n",
            "\n",
            "for paper in papers_gpt4:\n",
            "    print(f'Title: {paper[0]}')\n",
            "    print(f'Link: {paper[1]}')\n",
            "    print()\n",
            "    \n",
            "# If there are no papers returned, print a message to the user\n",
            "if not papers_gpt4:\n",
            "    print('No papers on GPT-4 found on Arxiv.')\n",
            "```\n",
            "\n",
            "You can run this Python script to see the 5 latest papers related to GPT-4 on ArXiv. After we confirm the existence of such papers, we will find potential applications in software from these papers.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "Title: How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability\n",
            "Link: https://arxiv.orghttps://arxiv.org/abs/2401.13641\n",
            "\n",
            "Title: Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes\n",
            "Link: https://arxiv.orghttps://arxiv.org/abs/2401.13588\n",
            "\n",
            "Title: Research about the Ability of LLM in the Tamper-Detection Area\n",
            "Link: https://arxiv.orghttps://arxiv.org/abs/2401.13504\n",
            "\n",
            "Title: Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption\n",
            "Link: https://arxiv.orghttps://arxiv.org/abs/2401.13444\n",
            "\n",
            "Title: ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models\n",
            "Link: https://arxiv.orghttps://arxiv.org/abs/2401.13311\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Coder (to chat_manager):\n",
            "\n",
            "Thank you for running the script. We found several papers related to large language models such as GPT. However, none of them are specifically about GPT-4.\n",
            "\n",
            "To search for potential applications of these language models in software, we will need to read the abstracts of these papers one by one to collect relevant information. Here is a python code snippet to fetch the abstract of the first paper.\n",
            "\n",
            "```python\n",
            "# filename: arxiv_abstract_fetcher.py\n",
            "\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "\n",
            "def get_abstract(url):\n",
            "    response = requests.get(url)\n",
            "    soup = BeautifulSoup(response.content, 'html.parser')\n",
            "    \n",
            "    # Abstract is within the blockquote tag\n",
            "    return soup.find('blockquote', attrs={'class': 'abstract'}).text.strip()\n",
            "\n",
            "# The URL of the first paper\n",
            "first_paper_url = 'https://arxiv.org/abs/2401.13641'\n",
            "\n",
            "# Prints the title and abstract of the first paper\n",
            "print('Abstract:')\n",
            "print(get_abstract(first_paper_url))\n",
            "```\n",
            "\n",
            "You can run this python script to get the abstract of the first paper. If the abstract reveals potential applications in software, I will summarize that for you. If not, we will pull the abstracts of the next papers until we find relevant information.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "User_proxy (to chat_manager):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "Abstract:\n",
            "Abstract:Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning).\n",
            "The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of the automatic decisions in human scenarios. Experiments are carried out in order to evaluate the performance and robustness of ChatGPT, using popular public benchmarks and comparing the results with state-of-the-art methods in the field. The results achieved in this study show the potential of LLMs such as ChatGPT for face biometrics, especially to enhance explainability. For reproducibility reasons, we release all the code in GitHub.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Product_manager (to chat_manager):\n",
            "\n",
            "Based on the abstract you shared, here are some potential applications of GPT-4, particularly as it is expressed in ChatGPT, in software:\n",
            "\n",
            "1. __Face Verification__: Face verification software could benefit from the integration of streamlined language models, enhancing user interaction and improving explanation of the verification process. The enhanced capability in handling natural language could possibly improve communication between such software and the end users.\n",
            "\n",
            "2. __Soft-Biometrics Estimation__: In bioinformatics and personal identification systems, GPT-4 could be used to estimate soft biometrics like gender, age, or ethnicity. This could lead to more efficient and natural interaction with users.\n",
            "\n",
            "3. __Explainability of Results__: Any software that uses complex algorithms to make decisions or predictions could use ChatGPT to communicate these results to users in an understandable manner. This involves providing clear, natural language explanations of how these algorithms arrived at their decisions, enhancing user trust and understanding.\n",
            "\n",
            "4. __Zero-Shot Learning__: Software applications, such as those needing to solve problems they have not been explicitly trained to handle, could benefit from the zero-shot learning capabilities of GPT-4. This would allow software to solve new problems with little to no prior exposure to similar tasks. This could apply to a wide range of software applications, from virtual assistants and recommendation systems to diagnostic tools and analytics software.\n",
            "\n",
            "5. __Virtual Assistants__: With the ability to process and generate natural language, GPT-4 could enhance the capabilities of virtual personal assistants, providing more accurate and human-like responses. \n",
            "\n",
            "Remember though, these are just extrapolations based on an abstract. The real potential can't be fully realized until you dive deep into the specifics of the paper and the technical details of the model.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        }
      ],
      "source": [
        "user_proxy.initiate_chat(\n",
        "    manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\"\n",
        ")\n",
        "# type exit to terminate the chat"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "flaml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}